{'acc': tensor(98), 'state_dict': OrderedDict([('conv1.weight', tensor([[[[ 7.1941e-01,  6.1723e-01,  5.9147e-01,  7.8368e-01,  8.2304e-01],
          [ 3.5908e-01,  4.3167e-01,  4.4066e-01,  2.9199e-01,  3.1020e-01],
          [-9.1980e-02, -1.2338e-02, -1.1774e-01, -2.7835e-01, -2.4555e-01],
          [-1.5425e-01, -9.7644e-03, -1.7802e-01, -1.0093e-02, -2.5680e-01],
          [-6.1751e-01, -3.3699e-01, -2.5267e-01, -2.3288e-01, -3.8341e-01]]],


        [[[-5.6893e-01,  5.1164e-01,  8.9382e-01,  1.0731e-01,  6.4422e-02],
          [-5.3381e-01,  1.0052e+00,  5.8471e-02, -2.0353e-01, -1.6398e-01],
          [-3.2062e-01,  1.4291e+00, -4.0591e-01,  6.2568e-03, -1.2384e-01],
          [ 7.2229e-02,  3.5893e-01, -1.9681e-01,  4.2521e-03, -1.9228e-01],
          [ 7.2410e-01,  9.6441e-02, -5.9417e-02, -6.6232e-03, -2.6831e-01]]],


        [[[-3.4782e-01, -2.8585e-02,  9.0651e-02,  5.3321e-01,  5.9555e-01],
          [-1.3592e-01, -9.3995e-02, -4.9760e-02,  9.1276e-01, -4.6975e-01],
          [-3.1452e-01, -1.3916e-01,  9.3479e-01,  7.0076e-01, -5.1080e-01],
          [-2.7374e-01, -1.3002e-01,  9.1414e-01, -6.7293e-02, -4.0243e-01],
          [ 3.4531e-02,  6.1743e-01,  6.7314e-01,  1.2108e-01, -3.9257e-01]]],


        [[[ 2.1760e-01,  4.1809e-01,  5.0822e-01,  2.5798e-01,  6.2615e-01],
          [-1.9336e-01,  1.3685e-01,  3.6299e-01,  2.6088e-01,  3.6217e-01],
          [-3.0106e-01, -1.8858e-02,  2.6602e-01,  1.1455e-01,  2.7466e-01],
          [-3.1428e-01, -3.8303e-01, -2.1488e-01, -5.8077e-02, -1.5559e-01],
          [-5.7552e-01, -5.0665e-01, -5.0484e-01, -3.9939e-01, -5.0975e-01]]],


        [[[-3.3512e-01,  2.0168e-01,  1.0289e+00,  3.8288e-01, -2.1649e-01],
          [-5.5115e-01,  3.2813e-01,  7.3176e-01, -2.6015e-01, -2.5153e-01],
          [-5.2978e-01,  1.1601e+00,  4.6202e-01, -1.9617e-01, -1.6071e-01],
          [-4.6301e-01,  8.2394e-01, -2.0365e-01, -8.8172e-03, -2.6089e-01],
          [ 3.7475e-01,  7.3101e-01,  6.8566e-02, -1.4295e-02, -2.3320e-01]]],


        [[[-2.5109e-01,  1.0035e-01,  3.1428e-01,  3.6997e-01,  7.2986e-01],
          [-2.5786e-01,  4.1377e-01,  6.2351e-01,  3.5851e-01,  4.7526e-01],
          [-1.4112e-01,  3.1173e-01,  3.4322e-01,  4.0357e-02, -6.4708e-03],
          [-5.2917e-01, -1.6660e-01, -1.6225e-01,  5.7001e-03, -1.3889e-01],
          [-6.2195e-01, -4.7004e-01, -4.1627e-01, -3.3230e-01, -5.4273e-01]]],


        [[[-4.4632e-01, -5.4737e-02, -1.9398e-01, -1.1711e-01, -3.3822e-01],
          [-6.8291e-02, -3.9551e-02, -1.1248e-02,  1.7053e-01, -1.3434e-01],
          [-2.1155e-01, -1.1824e-01, -1.3393e-01, -3.8696e-02, -3.2733e-01],
          [ 2.6918e-01, -1.2209e-01, -5.9330e-02, -8.8680e-02, -4.9949e-02],
          [ 9.2088e-01,  7.2224e-01,  7.3752e-01,  6.7014e-01,  9.9956e-01]]],


        [[[ 2.2362e-01,  4.0749e-01,  3.8069e-01,  2.0298e-01,  4.7133e-01],
          [-4.6099e-01,  3.3124e-02,  5.6801e-02,  1.0928e-01, -2.8134e-02],
          [-6.0304e-01, -8.3794e-01, -1.0869e+00, -6.5492e-01, -6.9713e-01],
          [-1.4299e-01, -2.6570e-02, -8.5249e-02,  3.9520e-02, -2.5402e-01],
          [ 4.7055e-01,  4.8177e-01,  3.6146e-01,  4.0339e-01, -4.4229e-02]]],


        [[[ 4.6483e-01,  1.7631e-01,  3.7641e-01,  1.7915e-01,  5.2858e-01],
          [ 1.0004e-01,  5.0238e-02,  7.0435e-02,  8.7145e-02,  2.8851e-01],
          [ 3.0413e-02,  2.1040e-01,  5.9091e-02,  3.3650e-01,  4.8271e-01],
          [-2.1247e-01, -9.5657e-03, -1.8648e-01, -1.9536e-01,  1.4057e-01],
          [-9.6237e-01, -5.6929e-01, -8.3510e-01, -8.1929e-01, -7.0870e-01]]],


        [[[ 4.8201e-01,  3.3212e-01,  3.0195e-01,  2.2777e-01,  5.7978e-01],
          [ 2.0446e-01,  2.7010e-02,  1.9828e-01, -5.9612e-02,  2.4102e-01],
          [ 2.7129e-01,  1.6884e-01,  1.9793e-01,  2.2418e-01,  2.8800e-01],
          [-3.7419e-01, -1.0123e-01, -1.6211e-01, -1.6158e-01, -1.3596e-01],
          [-8.2455e-01, -7.9235e-01, -7.6534e-01, -6.4571e-01, -6.4255e-01]]],


        [[[-9.9445e-02, -1.0807e-01,  3.6848e-03,  3.7383e-01,  6.2724e-01],
          [-2.6448e-01,  1.5961e-02, -1.4046e-01,  5.6216e-01, -1.6062e-01],
          [-1.0898e-01,  3.1775e-04, -3.3875e-01,  1.6572e+00, -5.6004e-01],
          [-2.1996e-01, -1.2208e-01,  5.0809e-02,  8.4200e-01, -5.8469e-01],
          [-1.2749e-01,  1.7344e-02,  7.8611e-01,  5.5959e-01, -3.4851e-01]]],


        [[[-4.5853e-01, -6.6731e-01, -2.1839e-03, -1.7829e-02,  6.7812e-02],
          [-6.4771e-01, -2.8974e-02,  4.6519e-01,  1.6419e-01,  2.1698e-02],
          [-1.2104e+00,  5.4846e-02,  4.5115e-01,  1.8955e-03,  2.0271e-01],
          [-1.0399e+00,  1.6608e-01,  3.2486e-01,  9.6393e-02,  3.7481e-01],
          [-1.2346e+00, -1.3163e-01,  3.3550e-02, -2.2463e-01,  2.2028e-01]]],


        [[[ 5.2991e-01,  3.0648e-01,  4.0298e-01,  4.0385e-01,  3.2571e-01],
          [-6.7296e-02, -4.3292e-01, -6.1880e-02,  1.6136e-01,  4.2256e-01],
          [-2.1658e-01, -4.4317e-01, -6.2850e-01, -1.5869e-01,  3.8965e-01],
          [-4.1222e-01, -2.6968e-01, -2.1296e-01, -1.3907e-02,  3.4796e-01],
          [-7.2030e-01, -3.8973e-01, -2.5194e-01, -8.7383e-02,  3.8474e-01]]],


        [[[ 3.7598e-01,  1.1432e-01,  1.9925e-01,  8.5889e-02,  3.7022e-01],
          [ 5.6333e-02, -3.5632e-02,  2.1304e-02, -2.1749e-01,  1.6947e-01],
          [ 1.7057e-02,  1.9111e-01,  1.6491e-01,  1.5016e-01,  3.2472e-01],
          [-3.9821e-01,  8.4866e-02,  4.3876e-02,  1.1752e-01, -1.3965e-01],
          [-1.0460e+00, -8.3122e-01, -1.0920e+00, -9.1820e-01, -1.1992e+00]]],


        [[[ 5.2527e-01,  1.6616e-01,  1.1650e-01,  3.1841e-01,  5.9053e-01],
          [ 4.7292e-02, -1.9049e-01, -3.7564e-01, -9.0890e-03,  2.7432e-01],
          [-2.0483e-01, -4.8361e-01, -4.1897e-01, -3.5196e-01,  3.0417e-01],
          [-2.2296e-01, -2.0170e-01, -2.7976e-01, -2.2639e-01,  2.2809e-01],
          [-1.0105e+00, -1.6858e-01, -4.8662e-03, -1.9970e-03,  5.3935e-01]]],


        [[[-3.9435e-01, -2.0883e-01, -1.6660e-01, -1.6455e-01, -3.3781e-01],
          [-2.2424e-02, -5.7260e-02,  9.2086e-02,  1.2854e-01, -1.9542e-01],
          [-9.3771e-03, -2.7643e-01, -2.6244e-01, -1.1919e-01, -4.0236e-01],
          [ 4.1511e-01, -4.3699e-02, -6.5553e-02, -4.8185e-02,  1.6091e-01],
          [ 1.0706e+00,  9.4667e-01,  1.1010e+00,  8.6729e-01,  1.2080e+00]]],


        [[[-5.1129e-01, -1.3245e-01, -1.9985e-01, -2.0303e-01, -3.2234e-01],
          [-2.0745e-01, -9.0519e-02, -1.2276e-01,  2.1411e-01, -2.1527e-01],
          [-2.0671e-01, -1.3039e-01, -1.5682e-01, -2.1525e-01, -2.8873e-01],
          [ 3.1611e-01, -1.0120e-01,  9.6612e-02, -5.2174e-02, -3.2454e-02],
          [ 9.2355e-01,  8.2598e-01,  5.7211e-01,  7.0789e-01,  9.1571e-01]]],


        [[[ 5.9472e-02, -4.3853e-01, -4.5605e-01, -2.8074e-01, -4.0413e-01],
          [ 4.6515e-01,  2.4331e-02, -5.1895e-04, -5.8662e-02, -2.0078e-02],
          [ 3.2704e-01,  8.1388e-01,  1.1851e+00,  6.4050e-01,  5.2019e-01],
          [-6.0689e-02,  2.7547e-02, -1.5967e-01, -8.5642e-02,  2.7964e-01],
          [-4.3637e-01, -4.6173e-01, -2.5689e-01, -3.4608e-01,  2.0180e-02]]],


        [[[ 2.6377e-01,  5.5885e-01,  7.2467e-01,  4.6937e-01,  9.1038e-01],
          [ 2.3174e-01,  3.1624e-01,  1.1699e-01,  1.8259e-01,  1.4574e-01],
          [ 1.5613e-01,  1.3193e-01,  1.3012e-01, -7.5751e-02, -6.3403e-02],
          [-2.4543e-01, -2.1770e-01, -3.5858e-01, -2.1043e-01, -3.5632e-01],
          [-9.7571e-01, -5.3703e-01, -2.5091e-01, -1.4303e-01, -2.5489e-01]]],


        [[[-5.2738e-01, -8.2806e-01, -5.0634e-01, -3.6856e-01, -5.0096e-01],
          [-3.0871e-01, -4.1602e-01, -2.1798e-01, -5.2317e-02,  1.1580e-01],
          [-3.5261e-01, -2.8904e-01,  1.2543e-01,  1.8325e-01,  2.2670e-01],
          [ 1.2005e-01,  7.4362e-02,  3.4196e-01,  6.8855e-02,  3.1984e-01],
          [ 6.5576e-01,  6.0229e-01,  2.7317e-01,  1.4158e-01,  4.7494e-01]]]],
       device='cuda:0')), ('conv1.bias', tensor([-1.0362e-04, -4.9573e-05,  1.1189e-04,  8.1387e-05, -3.4713e-05,
         4.8193e-05, -4.0413e-05, -8.8669e-05, -2.0339e-05,  4.7626e-05,
         4.0196e-05, -3.7421e-05, -1.3634e-04, -2.2925e-05,  5.4426e-05,
         5.2666e-05,  7.4815e-06, -1.4657e-05, -7.9764e-05,  4.6016e-05],
       device='cuda:0')), ('bn_conv1.weight', tensor([0.2828, 0.3982, 0.3813, 0.3180, 0.3768, 0.3022, 0.2527, 0.3560, 0.3191,
        0.3028, 0.3406, 0.3288, 0.3502, 0.2664, 0.3675, 0.2455, 0.3226, 0.3564,
        0.3076, 0.2809], device='cuda:0')), ('bn_conv1.bias', tensor([-1.0498e-04, -2.6022e-04, -3.4560e-04,  6.2704e-05,  3.3064e-06,
        -1.5470e-04, -7.3630e-06, -5.0125e-04, -4.3094e-04,  4.8889e-05,
         2.4397e-04,  2.5613e-05,  2.5893e-04,  4.8861e-04, -1.7271e-05,
        -1.0873e-04, -6.8968e-05, -2.1197e-04,  2.2345e-04,  2.5349e-04],
       device='cuda:0')), ('bn_conv1.running_mean', tensor([ 0.3713,  0.3987,  0.4847, -0.0642,  0.4557,  0.0040,  0.3438, -0.2310,
        -0.1668, -0.1687,  0.4046, -0.5237, -0.1285, -0.5984, -0.1890,  0.5679,
         0.2474,  0.1632,  0.1035, -0.1024], device='cuda:0')), ('bn_conv1.running_var', tensor([1.6143, 0.9410, 1.3323, 1.0334, 1.2550, 1.0600, 0.9401, 0.7067, 1.1859,
        1.2710, 0.9571, 1.6003, 0.9417, 1.6548, 0.8246, 1.7396, 1.0207, 0.5441,
        1.2923, 1.3077], device='cuda:0')), ('bn_conv1.num_batches_tracked', tensor(8911, device='cuda:0')), ('bin_ip1.bn.weight', tensor([1.5721, 1.7576, 1.8109, 1.5890, 1.8957, 1.4553, 1.7425, 1.8865, 1.5507,
        1.7205, 1.7932, 1.6992, 1.2856, 1.7022, 1.3800, 1.7481, 1.7684, 2.0878,
        1.8190, 1.5610], device='cuda:0')), ('bin_ip1.bn.bias', tensor([ 0.4526,  0.7289,  0.7532, -0.0954,  0.7625,  0.0156,  0.5681, -0.5920,
        -0.2471, -0.2660,  0.7454, -0.7008, -0.2329, -0.6896, -0.3091,  0.6881,
         0.4457,  0.6447,  0.1711, -0.1432], device='cuda:0')), ('bin_ip1.bn.running_mean', tensor([ 2.8249e-05, -1.4008e-04, -3.9466e-04,  9.2345e-06, -3.4658e-05,
         3.5499e-05, -4.0330e-05, -1.1962e-04, -3.5883e-04,  2.7915e-04,
         2.6113e-04, -6.8999e-05,  1.3589e-04,  6.5400e-05,  1.2397e-04,
        -1.3049e-04,  4.2800e-05, -2.1226e-04,  1.2712e-04,  1.8217e-04],
       device='cuda:0')), ('bin_ip1.bn.running_var', tensor([0.0799, 0.1588, 0.1456, 0.1012, 0.1424, 0.0914, 0.0645, 0.1266, 0.1020,
        0.0919, 0.1162, 0.1086, 0.1227, 0.0705, 0.1351, 0.0598, 0.1043, 0.1270,
        0.0948, 0.0790], device='cuda:0')), ('bin_ip1.bn.num_batches_tracked', tensor(8911, device='cuda:0')), ('bin_ip1.linear.weight', tensor([[ 0.0070, -0.0114,  0.0122,  ...,  0.0140,  0.0108, -0.0088],
        [ 0.0106, -0.0241, -0.0194,  ..., -0.0183, -0.0174,  0.0170],
        [-0.0044,  0.0048, -0.0121,  ..., -0.0009, -0.0025, -0.0047],
        ...,
        [-0.0212,  0.0183,  0.0215,  ..., -0.0250,  0.0140,  0.0145],
        [ 0.0380,  0.0365, -0.0442,  ...,  0.0172,  0.0163, -0.0539],
        [-0.0227,  0.0047, -0.0220,  ..., -0.0200, -0.0138, -0.0108]],
       device='cuda:0')), ('bin_ip1.linear.bias', tensor([ 0.2576,  0.0642,  0.1757,  0.3628,  0.0132,  0.1765,  0.1736, -0.2576,
         0.2112, -0.0242, -0.5907, -0.1160,  0.0999,  0.0009, -0.2037,  0.0952,
         0.0976,  0.0607,  0.2189, -0.1005, -0.2663, -0.0546,  0.3649, -0.0672,
        -0.0685, -0.5136, -0.2089, -0.6134, -0.0268,  0.1547,  0.1719,  0.6429,
        -0.0627, -0.0305, -0.3829, -0.2518,  0.3154,  0.3845, -0.1709,  0.0621],
       device='cuda:0')), ('ip2.weight', tensor([[-0.1046, -0.0332, -0.0844,  0.0410, -0.0097, -0.0289,  0.0991,  0.0908,
         -0.0378, -0.0455,  0.0118, -0.0191, -0.1665, -0.0372,  0.0175,  0.1022,
          0.0239,  0.0671, -0.0870,  0.2092,  0.1613, -0.1587, -0.0917, -0.0284,
          0.0350,  0.0278, -0.0008,  0.0986,  0.0828,  0.0933, -0.0058, -0.0587,
          0.1137, -0.0430,  0.0688,  0.0163, -0.0254, -0.0474,  0.0765, -0.1101],
        [ 0.0012,  0.0719,  0.0018, -0.0852,  0.0066, -0.0457,  0.2304, -0.2112,
          0.0362, -0.0204,  0.0382,  0.0459, -0.1438,  0.0945, -0.0182,  0.0513,
          0.1433,  0.0159,  0.0470,  0.0434,  0.1222, -0.0576,  0.1490, -0.0308,
         -0.0059,  0.0194, -0.1033, -0.0813, -0.0092, -0.0273,  0.0190, -0.0284,
          0.0955,  0.0244, -0.0437, -0.1108, -0.1505,  0.0095,  0.0392, -0.0739],
        [-0.0266,  0.0659, -0.0493,  0.2202, -0.0004, -0.0409,  0.2136, -0.0074,
         -0.0094, -0.0055,  0.0466,  0.0249, -0.1178, -0.0272,  0.0157,  0.0501,
          0.0792,  0.0654, -0.0872,  0.0661,  0.0121,  0.0395,  0.0816,  0.0451,
          0.0034,  0.0226, -0.0373, -0.1026,  0.0812, -0.0885,  0.0759,  0.0540,
          0.1186,  0.1111, -0.0373, -0.0948,  0.0513, -0.1173,  0.0877, -0.1221],
        [-0.0647,  0.0821, -0.0421,  0.0135, -0.0498, -0.0191,  0.1379, -0.0472,
          0.0030,  0.0170,  0.0723, -0.0126,  0.0348, -0.0270, -0.0623, -0.0331,
         -0.0807, -0.0106, -0.1357,  0.0540, -0.0589,  0.1705, -0.0073, -0.0189,
          0.0929, -0.0236,  0.0569,  0.0222,  0.0670, -0.0661,  0.0556, -0.0010,
          0.0967,  0.0328, -0.0945, -0.0564, -0.0469,  0.0285, -0.0552, -0.0617],
        [-0.0528,  0.0527, -0.1092,  0.0292,  0.0081, -0.0173,  0.0331, -0.0629,
         -0.0249, -0.0309,  0.0213,  0.0190, -0.1069,  0.0243,  0.0085,  0.0871,
          0.1349, -0.0302,  0.0228,  0.0471,  0.0244,  0.0273,  0.0400,  0.0492,
         -0.0751,  0.0240,  0.0362, -0.0069,  0.1116, -0.0488,  0.0045, -0.0259,
         -0.1065, -0.0283, -0.1605, -0.0260, -0.2925, -0.0332,  0.1614, -0.0087],
        [ 0.0274, -0.0326, -0.0712,  0.0044, -0.0110, -0.0199,  0.0804, -0.1564,
         -0.0271,  0.0131,  0.0092, -0.0397, -0.0760,  0.0296, -0.0603, -0.0364,
         -0.1347, -0.0335, -0.0415,  0.0660, -0.0669,  0.0512,  0.0303, -0.0971,
          0.0190, -0.0139, -0.0872, -0.1048,  0.0401,  0.0019,  0.0406, -0.0561,
         -0.0726, -0.0145,  0.1300, -0.0469, -0.1074,  0.0415, -0.0222, -0.0101],
        [-0.1078,  0.1001, -0.0980,  0.1054,  0.0305,  0.0057,  0.1054, -0.0511,
          0.0033,  0.0736,  0.0794,  0.0215, -0.0230,  0.0273,  0.0262,  0.0038,
          0.0579,  0.0873, -0.1227,  0.2275,  0.0232, -0.1219,  0.1557, -0.0788,
          0.0088, -0.0018, -0.0044, -0.1453,  0.1639,  0.1193, -0.0161, -0.0895,
          0.0427, -0.2633,  0.1250, -0.0866, -0.0652, -0.0249,  0.1348,  0.0040],
        [-0.0380, -0.0316, -0.1232,  0.0487, -0.0519, -0.0038,  0.2136, -0.0936,
          0.0017, -0.0215,  0.0221,  0.0185, -0.0032,  0.0615, -0.0540,  0.0043,
         -0.0181, -0.0012,  0.0472, -0.0333,  0.2560, -0.0490,  0.1333,  0.0497,
          0.0382, -0.0046, -0.0344,  0.0756, -0.0395, -0.1499,  0.0109, -0.0791,
         -0.0818,  0.0676, -0.0857,  0.0050, -0.0579,  0.0077,  0.0346, -0.1435],
        [-0.0295,  0.1202, -0.0161, -0.0368, -0.0026, -0.0107,  0.2569, -0.0406,
         -0.0350, -0.0928,  0.0375,  0.0028,  0.0209, -0.0549,  0.0247,  0.0009,
         -0.0663,  0.0144, -0.1057,  0.1162, -0.0246,  0.0132,  0.0771,  0.0093,
         -0.0459, -0.0167,  0.0351, -0.0487,  0.0148,  0.0145,  0.0278, -0.0895,
          0.0796, -0.0690,  0.0044, -0.0718, -0.0871,  0.0314,  0.1393, -0.0279],
        [ 0.0045,  0.0209, -0.1126,  0.0746,  0.0277, -0.0414,  0.1675, -0.0578,
          0.0072, -0.0564,  0.0148,  0.0590, -0.0951, -0.0093, -0.0165, -0.0488,
          0.0227, -0.0218,  0.0518,  0.0421,  0.0240,  0.1041,  0.0376,  0.0391,
          0.0903, -0.0023,  0.0107,  0.1238,  0.0415, -0.0765,  0.0008, -0.0208,
         -0.1311, -0.0419, -0.0105,  0.0237, -0.2047, -0.0529,  0.1323, -0.0867]],
       device='cuda:0')), ('ip2.bias', tensor([-1.7543, -0.0109,  0.6286,  0.4131, -0.4977,  1.2700, -1.3407,  0.1965,
         0.4712,  0.0850], device='cuda:0'))])}

Test set: Average loss: 0.0626, Accuracy: 9813/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.001
Train Epoch: 20 [0/60000 (0%)]	Loss: 0.026782
Train Epoch: 20 [12800/60000 (21%)]	Loss: 0.071997
Train Epoch: 20 [25600/60000 (43%)]	Loss: 0.028064
Train Epoch: 20 [38400/60000 (64%)]	Loss: 0.132402
Train Epoch: 20 [51200/60000 (85%)]	Loss: 0.018680

Test set: Average loss: 0.0642, Accuracy: 9810/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.001
Train Epoch: 21 [0/60000 (0%)]	Loss: 0.009569
Train Epoch: 21 [12800/60000 (21%)]	Loss: 0.036973
Train Epoch: 21 [25600/60000 (43%)]	Loss: 0.004488
Train Epoch: 21 [38400/60000 (64%)]	Loss: 0.021493
Train Epoch: 21 [51200/60000 (85%)]	Loss: 0.013132

Test set: Average loss: 0.0652, Accuracy: 9803/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.001
Train Epoch: 22 [0/60000 (0%)]	Loss: 0.028317
Train Epoch: 22 [12800/60000 (21%)]	Loss: 0.011172
Train Epoch: 22 [25600/60000 (43%)]	Loss: 0.092165
Train Epoch: 22 [38400/60000 (64%)]	Loss: 0.027402
Train Epoch: 22 [51200/60000 (85%)]	Loss: 0.019691

Test set: Average loss: 0.0653, Accuracy: 9791/10000 (97.00%)
Best Accuracy: 98.00%

Learning rate: 0.001
Train Epoch: 23 [0/60000 (0%)]	Loss: 0.014310
Train Epoch: 23 [12800/60000 (21%)]	Loss: 0.041210
Train Epoch: 23 [25600/60000 (43%)]	Loss: 0.027684
Train Epoch: 23 [38400/60000 (64%)]	Loss: 0.017481
Train Epoch: 23 [51200/60000 (85%)]	Loss: 0.012886

Test set: Average loss: 0.0711, Accuracy: 9802/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.001
Train Epoch: 24 [0/60000 (0%)]	Loss: 0.010778
Train Epoch: 24 [12800/60000 (21%)]	Loss: 0.038541
Train Epoch: 24 [25600/60000 (43%)]	Loss: 0.071007
Train Epoch: 24 [38400/60000 (64%)]	Loss: 0.012402
Train Epoch: 24 [51200/60000 (85%)]	Loss: 0.022955

Test set: Average loss: 0.0817, Accuracy: 9760/10000 (97.00%)
Best Accuracy: 98.00%

Learning rate: 0.001
Train Epoch: 25 [0/60000 (0%)]	Loss: 0.008765
Train Epoch: 25 [12800/60000 (21%)]	Loss: 0.033227
Train Epoch: 25 [25600/60000 (43%)]	Loss: 0.018480
Train Epoch: 25 [38400/60000 (64%)]	Loss: 0.100149
Train Epoch: 25 [51200/60000 (85%)]	Loss: 0.016001

Test set: Average loss: 0.1009, Accuracy: 9726/10000 (97.00%)
Best Accuracy: 98.00%

Learning rate: 0.001
Train Epoch: 26 [0/60000 (0%)]	Loss: 0.034646
Train Epoch: 26 [12800/60000 (21%)]	Loss: 0.074200
Train Epoch: 26 [25600/60000 (43%)]	Loss: 0.118723
Train Epoch: 26 [38400/60000 (64%)]	Loss: 0.050387
Train Epoch: 26 [51200/60000 (85%)]	Loss: 0.062725

Test set: Average loss: 0.0935, Accuracy: 9742/10000 (97.00%)
Best Accuracy: 98.00%

Learning rate: 0.001
Train Epoch: 27 [0/60000 (0%)]	Loss: 0.018259
Train Epoch: 27 [12800/60000 (21%)]	Loss: 0.025343
Train Epoch: 27 [25600/60000 (43%)]	Loss: 0.014747
Train Epoch: 27 [38400/60000 (64%)]	Loss: 0.235497
Train Epoch: 27 [51200/60000 (85%)]	Loss: 0.137750

Test set: Average loss: 0.1046, Accuracy: 9718/10000 (97.00%)
Best Accuracy: 98.00%

Learning rate: 0.001
Train Epoch: 28 [0/60000 (0%)]	Loss: 0.066877
Train Epoch: 28 [12800/60000 (21%)]	Loss: 0.028684
Train Epoch: 28 [25600/60000 (43%)]	Loss: 0.032150
Train Epoch: 28 [38400/60000 (64%)]	Loss: 0.044516
Train Epoch: 28 [51200/60000 (85%)]	Loss: 0.046906

Test set: Average loss: 0.1191, Accuracy: 9695/10000 (96.00%)
Best Accuracy: 98.00%

Learning rate: 0.001
Train Epoch: 29 [0/60000 (0%)]	Loss: 0.039244
Train Epoch: 29 [12800/60000 (21%)]	Loss: 0.061046
Train Epoch: 29 [25600/60000 (43%)]	Loss: 0.043698
Train Epoch: 29 [38400/60000 (64%)]	Loss: 0.021306
Train Epoch: 29 [51200/60000 (85%)]	Loss: 0.069568

Test set: Average loss: 0.0918, Accuracy: 9734/10000 (97.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 30 [0/60000 (0%)]	Loss: 0.048188
Train Epoch: 30 [12800/60000 (21%)]	Loss: 0.024313
Train Epoch: 30 [25600/60000 (43%)]	Loss: 0.007289
Train Epoch: 30 [38400/60000 (64%)]	Loss: 0.002135
Train Epoch: 30 [51200/60000 (85%)]	Loss: 0.030672

Test set: Average loss: 0.0812, Accuracy: 9776/10000 (97.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 31 [0/60000 (0%)]	Loss: 0.007748
Train Epoch: 31 [12800/60000 (21%)]	Loss: 0.026475
Train Epoch: 31 [25600/60000 (43%)]	Loss: 0.034018
Train Epoch: 31 [38400/60000 (64%)]	Loss: 0.080844
Train Epoch: 31 [51200/60000 (85%)]	Loss: 0.020231

Test set: Average loss: 0.0693, Accuracy: 9794/10000 (97.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 32 [0/60000 (0%)]	Loss: 0.013467
Train Epoch: 32 [12800/60000 (21%)]	Loss: 0.017753
Train Epoch: 32 [25600/60000 (43%)]	Loss: 0.072201
Train Epoch: 32 [38400/60000 (64%)]	Loss: 0.047991
Train Epoch: 32 [51200/60000 (85%)]	Loss: 0.033672

Test set: Average loss: 0.0771, Accuracy: 9796/10000 (97.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 33 [0/60000 (0%)]	Loss: 0.005375
Train Epoch: 33 [12800/60000 (21%)]	Loss: 0.039764
Train Epoch: 33 [25600/60000 (43%)]	Loss: 0.003244
Train Epoch: 33 [38400/60000 (64%)]	Loss: 0.027587
Train Epoch: 33 [51200/60000 (85%)]	Loss: 0.011972

Test set: Average loss: 0.0675, Accuracy: 9810/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 34 [0/60000 (0%)]	Loss: 0.025296
Train Epoch: 34 [12800/60000 (21%)]	Loss: 0.051007
Train Epoch: 34 [25600/60000 (43%)]	Loss: 0.004496
Train Epoch: 34 [38400/60000 (64%)]	Loss: 0.037674
Train Epoch: 34 [51200/60000 (85%)]	Loss: 0.005589

Test set: Average loss: 0.0658, Accuracy: 9800/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 35 [0/60000 (0%)]	Loss: 0.134917
Train Epoch: 35 [12800/60000 (21%)]	Loss: 0.005505
Train Epoch: 35 [25600/60000 (43%)]	Loss: 0.048841
Train Epoch: 35 [38400/60000 (64%)]	Loss: 0.009840
Train Epoch: 35 [51200/60000 (85%)]	Loss: 0.034974

Test set: Average loss: 0.0635, Accuracy: 9802/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 36 [0/60000 (0%)]	Loss: 0.021458
Train Epoch: 36 [12800/60000 (21%)]	Loss: 0.010474
Train Epoch: 36 [25600/60000 (43%)]	Loss: 0.006871
Train Epoch: 36 [38400/60000 (64%)]	Loss: 0.028338
Train Epoch: 36 [51200/60000 (85%)]	Loss: 0.007480

Test set: Average loss: 0.0656, Accuracy: 9808/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 37 [0/60000 (0%)]	Loss: 0.015430
Train Epoch: 37 [12800/60000 (21%)]	Loss: 0.021169
Train Epoch: 37 [25600/60000 (43%)]	Loss: 0.017891
Train Epoch: 37 [38400/60000 (64%)]	Loss: 0.004205
Train Epoch: 37 [51200/60000 (85%)]	Loss: 0.019503

Test set: Average loss: 0.0660, Accuracy: 9800/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 38 [0/60000 (0%)]	Loss: 0.005600
Train Epoch: 38 [12800/60000 (21%)]	Loss: 0.004073
Train Epoch: 38 [25600/60000 (43%)]	Loss: 0.029515
Train Epoch: 38 [38400/60000 (64%)]	Loss: 0.029327
Train Epoch: 38 [51200/60000 (85%)]	Loss: 0.001666

Test set: Average loss: 0.0683, Accuracy: 9805/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 39 [0/60000 (0%)]	Loss: 0.004358
Train Epoch: 39 [12800/60000 (21%)]	Loss: 0.015244
Train Epoch: 39 [25600/60000 (43%)]	Loss: 0.025992
Train Epoch: 39 [38400/60000 (64%)]	Loss: 0.014953
Train Epoch: 39 [51200/60000 (85%)]	Loss: 0.001707

Test set: Average loss: 0.0651, Accuracy: 9803/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 40 [0/60000 (0%)]	Loss: 0.005860
Train Epoch: 40 [12800/60000 (21%)]	Loss: 0.014390
Train Epoch: 40 [25600/60000 (43%)]	Loss: 0.016032
Train Epoch: 40 [38400/60000 (64%)]	Loss: 0.006812
Train Epoch: 40 [51200/60000 (85%)]	Loss: 0.004847

Test set: Average loss: 0.0669, Accuracy: 9813/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 41 [0/60000 (0%)]	Loss: 0.010770
Train Epoch: 41 [12800/60000 (21%)]	Loss: 0.015005
Train Epoch: 41 [25600/60000 (43%)]	Loss: 0.013636
Train Epoch: 41 [38400/60000 (64%)]	Loss: 0.018537
Train Epoch: 41 [51200/60000 (85%)]	Loss: 0.020078

Test set: Average loss: 0.0627, Accuracy: 9814/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 42 [0/60000 (0%)]	Loss: 0.008280
Train Epoch: 42 [12800/60000 (21%)]	Loss: 0.015588
Train Epoch: 42 [25600/60000 (43%)]	Loss: 0.004705
Train Epoch: 42 [38400/60000 (64%)]	Loss: 0.008816
Train Epoch: 42 [51200/60000 (85%)]	Loss: 0.028308

Test set: Average loss: 0.0723, Accuracy: 9796/10000 (97.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 43 [0/60000 (0%)]	Loss: 0.002526
Train Epoch: 43 [12800/60000 (21%)]	Loss: 0.011168
Train Epoch: 43 [25600/60000 (43%)]	Loss: 0.004716
Train Epoch: 43 [38400/60000 (64%)]	Loss: 0.005492
Train Epoch: 43 [51200/60000 (85%)]	Loss: 0.008308

Test set: Average loss: 0.0642, Accuracy: 9828/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 0.0001
Train Epoch: 44 [0/60000 (0%)]	Loss: 0.029437
Train Epoch: 44 [12800/60000 (21%)]	Loss: 0.018584
Train Epoch: 44 [25600/60000 (43%)]	Loss: 0.032927
Train Epoch: 44 [38400/60000 (64%)]	Loss: 0.003592
Train Epoch: 44 [51200/60000 (85%)]	Loss: 0.007288

Test set: Average loss: 0.0624, Accuracy: 9810/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 45 [0/60000 (0%)]	Loss: 0.011926
Train Epoch: 45 [12800/60000 (21%)]	Loss: 0.009119
Train Epoch: 45 [25600/60000 (43%)]	Loss: 0.040024
Train Epoch: 45 [38400/60000 (64%)]	Loss: 0.023339
Train Epoch: 45 [51200/60000 (85%)]	Loss: 0.034160

Test set: Average loss: 0.0613, Accuracy: 9810/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 46 [0/60000 (0%)]	Loss: 0.005281
Train Epoch: 46 [12800/60000 (21%)]	Loss: 0.009668
Train Epoch: 46 [25600/60000 (43%)]	Loss: 0.032844
Train Epoch: 46 [38400/60000 (64%)]	Loss: 0.012960
Train Epoch: 46 [51200/60000 (85%)]	Loss: 0.021461

Test set: Average loss: 0.0630, Accuracy: 9808/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 47 [0/60000 (0%)]	Loss: 0.008249
Train Epoch: 47 [12800/60000 (21%)]	Loss: 0.024624
Train Epoch: 47 [25600/60000 (43%)]	Loss: 0.008716
Train Epoch: 47 [38400/60000 (64%)]	Loss: 0.026789
Train Epoch: 47 [51200/60000 (85%)]	Loss: 0.012404

Test set: Average loss: 0.0629, Accuracy: 9808/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 48 [0/60000 (0%)]	Loss: 0.008036
Train Epoch: 48 [12800/60000 (21%)]	Loss: 0.003465
Train Epoch: 48 [25600/60000 (43%)]	Loss: 0.007112
Train Epoch: 48 [38400/60000 (64%)]	Loss: 0.007976
Train Epoch: 48 [51200/60000 (85%)]	Loss: 0.002324

Test set: Average loss: 0.0611, Accuracy: 9816/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 49 [0/60000 (0%)]	Loss: 0.003499
Train Epoch: 49 [12800/60000 (21%)]	Loss: 0.007994
Train Epoch: 49 [25600/60000 (43%)]	Loss: 0.012036
Train Epoch: 49 [38400/60000 (64%)]	Loss: 0.011827
Train Epoch: 49 [51200/60000 (85%)]	Loss: 0.005759

Test set: Average loss: 0.0612, Accuracy: 9831/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 50 [0/60000 (0%)]	Loss: 0.025331
Train Epoch: 50 [12800/60000 (21%)]	Loss: 0.012819
Train Epoch: 50 [25600/60000 (43%)]	Loss: 0.022731
Train Epoch: 50 [38400/60000 (64%)]	Loss: 0.012198
Train Epoch: 50 [51200/60000 (85%)]	Loss: 0.019186

Test set: Average loss: 0.0701, Accuracy: 9808/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 51 [0/60000 (0%)]	Loss: 0.017797
Train Epoch: 51 [12800/60000 (21%)]	Loss: 0.002139
Train Epoch: 51 [25600/60000 (43%)]	Loss: 0.005927
Train Epoch: 51 [38400/60000 (64%)]	Loss: 0.009939
Train Epoch: 51 [51200/60000 (85%)]	Loss: 0.002497

Test set: Average loss: 0.0703, Accuracy: 9808/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 52 [0/60000 (0%)]	Loss: 0.004243
Train Epoch: 52 [12800/60000 (21%)]	Loss: 0.033186
Train Epoch: 52 [25600/60000 (43%)]	Loss: 0.017870
Train Epoch: 52 [38400/60000 (64%)]	Loss: 0.005823
Train Epoch: 52 [51200/60000 (85%)]	Loss: 0.001425

Test set: Average loss: 0.0652, Accuracy: 9816/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 53 [0/60000 (0%)]	Loss: 0.012659
Train Epoch: 53 [12800/60000 (21%)]	Loss: 0.017117
Train Epoch: 53 [25600/60000 (43%)]	Loss: 0.010463
Train Epoch: 53 [38400/60000 (64%)]	Loss: 0.002152
Train Epoch: 53 [51200/60000 (85%)]	Loss: 0.019305

Test set: Average loss: 0.0615, Accuracy: 9815/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 54 [0/60000 (0%)]	Loss: 0.012265
Train Epoch: 54 [12800/60000 (21%)]	Loss: 0.047746
Train Epoch: 54 [25600/60000 (43%)]	Loss: 0.016164
Train Epoch: 54 [38400/60000 (64%)]	Loss: 0.026272
Train Epoch: 54 [51200/60000 (85%)]	Loss: 0.006129

Test set: Average loss: 0.0682, Accuracy: 9820/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 55 [0/60000 (0%)]	Loss: 0.009515
Train Epoch: 55 [12800/60000 (21%)]	Loss: 0.012674
Train Epoch: 55 [25600/60000 (43%)]	Loss: 0.006433
Train Epoch: 55 [38400/60000 (64%)]	Loss: 0.009946
Train Epoch: 55 [51200/60000 (85%)]	Loss: 0.008308

Test set: Average loss: 0.0648, Accuracy: 9820/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 56 [0/60000 (0%)]	Loss: 0.012069
Train Epoch: 56 [12800/60000 (21%)]	Loss: 0.005484
Train Epoch: 56 [25600/60000 (43%)]	Loss: 0.015441
Train Epoch: 56 [38400/60000 (64%)]	Loss: 0.007065
Train Epoch: 56 [51200/60000 (85%)]	Loss: 0.015590

Test set: Average loss: 0.0609, Accuracy: 9817/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 57 [0/60000 (0%)]	Loss: 0.005121
Train Epoch: 57 [12800/60000 (21%)]	Loss: 0.008790
Train Epoch: 57 [25600/60000 (43%)]	Loss: 0.000707
Train Epoch: 57 [38400/60000 (64%)]	Loss: 0.010958
Train Epoch: 57 [51200/60000 (85%)]	Loss: 0.005148

Test set: Average loss: 0.0673, Accuracy: 9804/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 58 [0/60000 (0%)]	Loss: 0.008618
Train Epoch: 58 [12800/60000 (21%)]	Loss: 0.004249
Train Epoch: 58 [25600/60000 (43%)]	Loss: 0.021732
Train Epoch: 58 [38400/60000 (64%)]	Loss: 0.007487
Train Epoch: 58 [51200/60000 (85%)]	Loss: 0.007485

Test set: Average loss: 0.0683, Accuracy: 9811/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-05
Train Epoch: 59 [0/60000 (0%)]	Loss: 0.004637
Train Epoch: 59 [12800/60000 (21%)]	Loss: 0.003255
Train Epoch: 59 [25600/60000 (43%)]	Loss: 0.009577
Train Epoch: 59 [38400/60000 (64%)]	Loss: 0.010582
Train Epoch: 59 [51200/60000 (85%)]	Loss: 0.008645

Test set: Average loss: 0.0630, Accuracy: 9822/10000 (98.00%)
Best Accuracy: 98.00%

Learning rate: 1e-06
Train Epoch: 60 [0/60000 (0%)]	Loss: 0.005370
Train Epoch: 60 [12800/60000 (21%)]	Loss: 0.012902
Train Epoch: 60 [25600/60000 (43%)]	Loss: 0.019351
Train Epoch: 60 [38400/60000 (64%)]	Loss: 0.003156
Train Epoch: 60 [51200/60000 (85%)]	Loss: 0.003142

Test set: Average loss: 0.0673, Accuracy: 9805/10000 (98.00%)
Best Accuracy: 98.00%

